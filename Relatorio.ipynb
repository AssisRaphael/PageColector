{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relatório TP1 - ☯ Coding Dojo ☯\n",
    "\n",
    "**Alunos:**\n",
    "* José Antônio Carneiro Ávila\n",
    "* Gleiston Guimarães de Assis Filho\n",
    "* Rafael Silvério de Sá Lopes\n",
    "* Raphael de Assis Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principais desafios, decisões e arquitetura utilizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na realização deste trabalho foi implementado um page fetcher e um escalonador para coletar páginas de diversos domínios na internet. Os principais desafios encontrados estão relacionados à performance da aplicação. A fim de paralelizar os downloads das páginas e aumentar a velocidade da coleta, desenvolveu-se os métodos da classe do page fetcher como assincronos. Dessa forma, pode-se criar vários page fetchers para baixar as páginas dos domínios escolhidos, tornando a busca escalável.\n",
    "\n",
    "Na arquitetura implementada, a classe escalonador gerencia as páginas visitadas e define quais serão as próximas URLs a serem visitadas. Por outro lado, a classe page fetcher visita cada página selecionada e realiza o download de seu conteúdo. A partir da análise de cada página, coleta-se mais URLs que poderão ser visitadas futuramente, de acordo com a priorização feita pelo escalonador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs sementes utilizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sementes escolhidas para os testes:\n",
    "* https://translate.google.com.br/\n",
    "* https://www.invertexto.com/contador-caracteres\n",
    "* https://www.americanas.com.br/\n",
    "* http://www.google.com.br\n",
    "* https://www.folha.uol.com.br/\n",
    "\n",
    "Essas páginas foram escolhidas de forma a testar bem o funcionamento do código. As primeiras páginas possuem poucos links para outras páginas, o que é bom para testarmos se o código esta de fato passando por todos os domínios selecionados. As últimas páginas escolhidas possuem muitos links como o site da Folha de São Paulo, o que é bom para testarmos a performance do coletor de links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como foi feito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classe domain representa os domínios da nossa aplicação e possui três atributos principais, são eles:\n",
    "* int_time_limit_between_requests, que representa o tempo de espera entre as requisições das páginas desse domínio;\n",
    "* nam_domain, que representa o nome do domínio;\n",
    "* time_last_access, que representa o horário do último acesso à páginas deste domínio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheduler (Escalonador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O esquema de armazenamento do coletor é feita por um dicionário e esta ilustrada na imagem abaixo.\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "    <img src=\"imgs/estrutura_coletor.png\">\n",
    "    <caption>Fonte: Baeza-Yates e Ribeiro-Neto, 2011 </caption>\n",
    "</figure>\n",
    "\n",
    "Na ilustração acima, cada chave do dicionário é um objeto da classe Domain. Os valores do dicionário é uma lista de tuplas com a URL a da página a ser pesquisada e sua profundidade no domínio.\n",
    "\n",
    "Organizamos as informações dos domínios das páginas coletadas em uma classe chamada scheduler (escalonador). Esta classe é responsável por armazenar as URLs das páginas descobertas e os metadados relacionados à elas, como a profundidade da página em seu domínio principal e se essa página pode ser pesquisada obedecendo as regras do robots.txt. O escalonador também é responsável por controlar o tempo de requisição de páginas em um mesmo domínio, garantindo que não será feito muitas requisições em pouco intervalo de tempo. Por fim, também é responsábilidade do escalonador determinar os critérios de finalização da busca, seja por limite de páginas pesquisadas, por tempo de busca ou por limite de profundidade da coleta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Page fecther"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Page fetcher é a classe que visita as URLs dadas pelo escalonador e obtêm as páginas referenciadas por elas. Para atingir tal objetivo analisa-se o conteúdo HTML da página e extrai-se os links contidos nos atributos *href* nas tags *a*. Identificados esses links,enviamos para o escalonador adicionar na lista de páginas a serem pesquisadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "from crawler.scheduler import *\n",
    "from crawler.page_fetcher import *\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def start_escalonador():\n",
    "    Escalonador = Scheduler(str_usr_agent=\"Wall-E\",\n",
    "                                    int_page_limit=10,\n",
    "                                    int_depth_limit=6,\n",
    "                                    arr_urls_seeds=[\"https://www.casasbahia.com.br\",\n",
    "                                                    \"https://www.r7.com\",\n",
    "                                                    \"https://www.americanas.com.br\",\n",
    "                                                    \"http://www.google.com.br\",\n",
    "                                                    \"https://www.folha.uol.com.br\"])\n",
    "\n",
    "    Escalonador.add_new_page(urlparse(\"https://www.casasbahia.com.br\"), 1)\n",
    "    Escalonador.add_new_page(urlparse(\"https://www.r7.com\"), 1)\n",
    "    Escalonador.add_new_page(urlparse(\"https://www.americanas.com.br\"), 1)\n",
    "    Escalonador.add_new_page(urlparse(\"http://www.google.com.br\"), 1)\n",
    "    Escalonador.add_new_page(urlparse(\"https://www.folha.uol.com.br\"), 1)\n",
    "\n",
    "    return Escalonador\n",
    "\n",
    "for threads in range(10,100,20):\n",
    "    Escalonador = start_escalonador()\n",
    "    tempoInicial = datetime.now()\n",
    "    fetchers = [PageFetcher(Escalonador) for i in range(threads)]\n",
    "    print(len(fetchers))\n",
    "    for f in fetchers:\n",
    "        f.run()\n",
    "    tempoFinal = datetime.now()\n",
    "    print(''*15,'\\n\\n')\n",
    "    print('Tempo total:',tempoFinal-tempoInicial,'\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
